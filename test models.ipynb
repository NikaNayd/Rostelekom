{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc0f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 45196.2305 - rmse: 50213.4297 - val_loss: 13922.2246 - val_rmse: 17111.1973\n",
      "Epoch 2/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 14631.8848 - rmse: 18032.5566 - val_loss: 12842.3545 - val_rmse: 15836.2002\n",
      "Epoch 3/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13862.9951 - rmse: 17220.5547 - val_loss: 12653.4756 - val_rmse: 15649.5049\n",
      "Epoch 4/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13748.6328 - rmse: 17074.9121 - val_loss: 12600.8994 - val_rmse: 15567.1982\n",
      "Epoch 5/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13662.9609 - rmse: 16983.5781 - val_loss: 12572.0303 - val_rmse: 15552.5410\n",
      "Epoch 6/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13742.6523 - rmse: 17069.7188 - val_loss: 12548.6543 - val_rmse: 15522.1865\n",
      "Epoch 7/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13559.2295 - rmse: 16912.4375 - val_loss: 12550.0049 - val_rmse: 15545.1426\n",
      "Epoch 8/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13557.4160 - rmse: 16840.3926 - val_loss: 12544.4590 - val_rmse: 15520.9756\n",
      "Epoch 9/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13476.2119 - rmse: 16808.0352 - val_loss: 12566.8623 - val_rmse: 15535.9854\n",
      "Epoch 10/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13456.3926 - rmse: 16778.4766 - val_loss: 12530.1104 - val_rmse: 15497.7871\n",
      "Epoch 11/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13435.0527 - rmse: 16763.4297 - val_loss: 12525.7793 - val_rmse: 15514.6406\n",
      "Epoch 12/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13548.1797 - rmse: 16849.2871 - val_loss: 12525.0293 - val_rmse: 15519.0146\n",
      "Epoch 13/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13500.3115 - rmse: 16827.9824 - val_loss: 12516.9531 - val_rmse: 15502.7178\n",
      "Epoch 14/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13529.0059 - rmse: 16858.4531 - val_loss: 12504.5195 - val_rmse: 15487.9395\n",
      "Epoch 15/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13426.5342 - rmse: 16739.8398 - val_loss: 12517.3770 - val_rmse: 15493.6777\n",
      "Epoch 16/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13466.8691 - rmse: 16807.8066 - val_loss: 12495.6084 - val_rmse: 15453.5146\n",
      "Epoch 17/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13418.1738 - rmse: 16699.1543 - val_loss: 12502.1973 - val_rmse: 15478.3975\n",
      "Epoch 18/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13424.0137 - rmse: 16710.3320 - val_loss: 12491.3154 - val_rmse: 15481.4404\n",
      "Epoch 19/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13426.9648 - rmse: 16741.8457 - val_loss: 12484.6221 - val_rmse: 15476.3145\n",
      "Epoch 20/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13469.7227 - rmse: 16788.6406 - val_loss: 12474.3828 - val_rmse: 15463.9346\n",
      "Epoch 21/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13416.9375 - rmse: 16747.1094 - val_loss: 12481.4697 - val_rmse: 15441.9795\n",
      "Epoch 22/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13376.5439 - rmse: 16686.3398 - val_loss: 12470.9219 - val_rmse: 15434.3936\n",
      "Epoch 23/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13489.5146 - rmse: 16811.9199 - val_loss: 12474.0615 - val_rmse: 15432.2490\n",
      "Epoch 24/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13297.0518 - rmse: 16605.7031 - val_loss: 12478.6455 - val_rmse: 15429.9199\n",
      "Epoch 25/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13336.4932 - rmse: 16629.3203 - val_loss: 12458.3213 - val_rmse: 15446.2246\n",
      "Epoch 26/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13380.8057 - rmse: 16668.3945 - val_loss: 12496.5605 - val_rmse: 15435.1973\n",
      "Epoch 27/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13409.4785 - rmse: 16758.9023 - val_loss: 12451.2705 - val_rmse: 15403.9502\n",
      "Epoch 28/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13461.6396 - rmse: 16740.1621 - val_loss: 12468.3857 - val_rmse: 15411.0576\n",
      "Epoch 29/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13460.9619 - rmse: 16749.7715 - val_loss: 12457.4541 - val_rmse: 15411.9160\n",
      "Epoch 30/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13413.6113 - rmse: 16716.3223 - val_loss: 12440.3926 - val_rmse: 15402.2666\n",
      "Epoch 31/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13489.4082 - rmse: 16820.9160 - val_loss: 12447.1748 - val_rmse: 15435.4463\n",
      "Epoch 32/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13409.5547 - rmse: 16679.0820 - val_loss: 12446.8848 - val_rmse: 15403.9297\n",
      "Epoch 33/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13401.0361 - rmse: 16692.8613 - val_loss: 12438.5469 - val_rmse: 15432.4824\n",
      "Epoch 34/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13487.9434 - rmse: 16787.0332 - val_loss: 12436.3955 - val_rmse: 15420.5127\n",
      "Epoch 35/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13424.4385 - rmse: 16711.3125 - val_loss: 12425.5596 - val_rmse: 15421.1836\n",
      "Epoch 36/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13369.4424 - rmse: 16669.8379 - val_loss: 12440.6025 - val_rmse: 15424.8281\n",
      "Epoch 37/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13364.6875 - rmse: 16682.6738 - val_loss: 12430.2324 - val_rmse: 15388.9209\n",
      "Epoch 38/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13245.4141 - rmse: 16573.9551 - val_loss: 12432.8330 - val_rmse: 15409.2861\n",
      "Epoch 39/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13394.7490 - rmse: 16725.2031 - val_loss: 12430.1953 - val_rmse: 15389.5088\n",
      "Epoch 40/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13248.8555 - rmse: 16507.6016 - val_loss: 12424.0869 - val_rmse: 15376.9326\n",
      "Epoch 41/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13346.4053 - rmse: 16640.1074 - val_loss: 12414.9590 - val_rmse: 15376.2910\n",
      "Epoch 42/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13335.2832 - rmse: 16630.4961 - val_loss: 12446.4189 - val_rmse: 15398.0215\n",
      "Epoch 43/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13308.9648 - rmse: 16628.9062 - val_loss: 12418.3506 - val_rmse: 15374.7598\n",
      "Epoch 44/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13359.0156 - rmse: 16666.2910 - val_loss: 12443.1973 - val_rmse: 15406.0586\n",
      "Epoch 45/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13284.2266 - rmse: 16541.7812 - val_loss: 12419.1221 - val_rmse: 15381.8760\n",
      "Epoch 46/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13329.9424 - rmse: 16620.7871 - val_loss: 12449.9482 - val_rmse: 15452.9775\n",
      "Epoch 47/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13271.6094 - rmse: 16540.2246 - val_loss: 12425.5371 - val_rmse: 15393.3496\n",
      "Epoch 48/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13267.5889 - rmse: 16579.5566 - val_loss: 12423.0645 - val_rmse: 15388.0576\n",
      "Epoch 49/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13315.4248 - rmse: 16584.6484 - val_loss: 12410.0244 - val_rmse: 15385.3857\n",
      "Epoch 50/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13215.9502 - rmse: 16461.6094 - val_loss: 12421.9629 - val_rmse: 15392.6699\n",
      "Epoch 51/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13472.0557 - rmse: 16741.2031 - val_loss: 12412.4150 - val_rmse: 15389.8691\n",
      "Epoch 52/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13347.7812 - rmse: 16688.4844 - val_loss: 12428.5400 - val_rmse: 15367.8564\n",
      "Epoch 53/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13295.3516 - rmse: 16570.0859 - val_loss: 12447.7012 - val_rmse: 15372.5605\n",
      "Epoch 54/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13296.3447 - rmse: 16556.2598 - val_loss: 12410.3555 - val_rmse: 15362.9150\n",
      "Epoch 55/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13366.0273 - rmse: 16660.7676 - val_loss: 12427.7822 - val_rmse: 15426.4971\n",
      "Epoch 56/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13269.0977 - rmse: 16541.8125 - val_loss: 12405.7471 - val_rmse: 15401.6377\n",
      "Epoch 57/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13312.3311 - rmse: 16573.0605 - val_loss: 12424.6123 - val_rmse: 15386.2129\n",
      "Epoch 58/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13301.8604 - rmse: 16597.3125 - val_loss: 12397.7061 - val_rmse: 15370.9541\n",
      "Epoch 59/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13315.0859 - rmse: 16626.1172 - val_loss: 12392.4941 - val_rmse: 15363.6279\n",
      "Epoch 60/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13312.1260 - rmse: 16558.3633 - val_loss: 12407.0234 - val_rmse: 15367.2100\n",
      "Epoch 61/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13286.0332 - rmse: 16569.7012 - val_loss: 12393.2119 - val_rmse: 15382.3965\n",
      "Epoch 62/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13218.0615 - rmse: 16545.5898 - val_loss: 12412.0723 - val_rmse: 15371.5957\n",
      "Epoch 63/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13259.2969 - rmse: 16533.8652 - val_loss: 12389.6777 - val_rmse: 15340.2295\n",
      "Epoch 64/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13375.8779 - rmse: 16649.0371 - val_loss: 12409.3721 - val_rmse: 15392.3779\n",
      "Epoch 65/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13324.4482 - rmse: 16626.3398 - val_loss: 12396.5869 - val_rmse: 15343.4238\n",
      "Epoch 66/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13212.1016 - rmse: 16472.0078 - val_loss: 12385.3232 - val_rmse: 15381.8740\n",
      "Epoch 67/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13196.5742 - rmse: 16524.4199 - val_loss: 12383.0859 - val_rmse: 15340.4707\n",
      "Epoch 68/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13297.2021 - rmse: 16580.1660 - val_loss: 12386.1572 - val_rmse: 15330.2646\n",
      "Epoch 69/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13390.3877 - rmse: 16711.4180 - val_loss: 12384.8643 - val_rmse: 15361.3965\n",
      "Epoch 70/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13237.1670 - rmse: 16528.0059 - val_loss: 12389.9941 - val_rmse: 15348.9160\n",
      "Epoch 71/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13300.1016 - rmse: 16539.2988 - val_loss: 12391.8936 - val_rmse: 15345.4092\n",
      "Epoch 72/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13248.0479 - rmse: 16548.2383 - val_loss: 12382.8838 - val_rmse: 15349.6963\n",
      "Epoch 73/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13249.5771 - rmse: 16500.2207 - val_loss: 12384.2100 - val_rmse: 15370.0752\n",
      "Epoch 74/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13290.8066 - rmse: 16570.6953 - val_loss: 12400.9121 - val_rmse: 15339.1084\n",
      "Epoch 75/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13211.0537 - rmse: 16496.0332 - val_loss: 12384.7178 - val_rmse: 15363.2021\n",
      "Epoch 76/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13189.0840 - rmse: 16504.8887 - val_loss: 12384.0488 - val_rmse: 15368.1270\n",
      "Epoch 77/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13210.4951 - rmse: 16466.5840 - val_loss: 12389.2012 - val_rmse: 15345.3525\n",
      "Epoch 78/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13350.6885 - rmse: 16659.9629 - val_loss: 12387.9258 - val_rmse: 15378.7969\n",
      "Epoch 79/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13283.4160 - rmse: 16581.6055 - val_loss: 12386.8027 - val_rmse: 15369.7246\n",
      "Epoch 80/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13359.9629 - rmse: 16647.8223 - val_loss: 12369.4121 - val_rmse: 15355.6484\n",
      "Epoch 81/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13311.7861 - rmse: 16572.0977 - val_loss: 12379.7354 - val_rmse: 15344.9375\n",
      "Epoch 82/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13233.1074 - rmse: 16549.0762 - val_loss: 12384.6270 - val_rmse: 15336.2842\n",
      "Epoch 83/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13116.6973 - rmse: 16362.8711 - val_loss: 12369.4707 - val_rmse: 15331.1035\n",
      "Epoch 84/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13235.7480 - rmse: 16522.8203 - val_loss: 12390.7656 - val_rmse: 15385.0225\n",
      "Epoch 85/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13305.6172 - rmse: 16605.8242 - val_loss: 12371.3691 - val_rmse: 15338.5879\n",
      "Epoch 86/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13316.3438 - rmse: 16574.0156 - val_loss: 12381.6855 - val_rmse: 15328.1152\n",
      "Epoch 87/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13220.6768 - rmse: 16478.3301 - val_loss: 12374.4844 - val_rmse: 15403.8398\n",
      "Epoch 88/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13283.7969 - rmse: 16600.0391 - val_loss: 12355.3613 - val_rmse: 15335.4512\n",
      "Epoch 89/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13247.2109 - rmse: 16514.7656 - val_loss: 12372.2227 - val_rmse: 15318.2480\n",
      "Epoch 90/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13211.3037 - rmse: 16481.5527 - val_loss: 12370.6416 - val_rmse: 15332.0352\n",
      "Epoch 91/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13221.2070 - rmse: 16452.4277 - val_loss: 12389.3115 - val_rmse: 15364.8154\n",
      "Epoch 92/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13155.5000 - rmse: 16453.3848 - val_loss: 12381.7148 - val_rmse: 15332.4746\n",
      "Epoch 93/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13222.2744 - rmse: 16534.1914 - val_loss: 12355.4922 - val_rmse: 15307.7949\n",
      "Epoch 94/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13168.9180 - rmse: 16439.4316 - val_loss: 12367.2686 - val_rmse: 15336.6338\n",
      "Epoch 95/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13245.7402 - rmse: 16520.8223 - val_loss: 12367.0518 - val_rmse: 15356.0322\n",
      "Epoch 96/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13167.1416 - rmse: 16442.5684 - val_loss: 12412.7334 - val_rmse: 15410.1582\n",
      "Epoch 97/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13301.0459 - rmse: 16585.8281 - val_loss: 12353.8896 - val_rmse: 15340.2686\n",
      "Epoch 98/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13268.9219 - rmse: 16609.2598 - val_loss: 12357.6367 - val_rmse: 15349.7295\n",
      "Epoch 99/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13217.8955 - rmse: 16525.6016 - val_loss: 12375.9727 - val_rmse: 15331.5654\n",
      "Epoch 100/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13178.8320 - rmse: 16395.5488 - val_loss: 12359.1221 - val_rmse: 15324.2871\n",
      "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step\n",
      "Deep Learning Model Test MAE: 12632.30\n",
      "Deep Learning Model Test R2:  0.234\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "df = pd.read_csv('/Users/maximbortnik/Downloads/dataset_with_company_count_M.csv', sep=';', low_memory=False)\n",
    "\n",
    "TARGET = 'salary.amount'\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "numeric_feats = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_feats = [c for c in X.columns if c not in numeric_feats]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_feats),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_feats)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "n_features = X_train_proc.shape[1]\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(n_features,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1) \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    ")\n",
    "\n",
    "es = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_proc, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test_proc).flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2  = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Deep Learning Model Test MAE: {:.2f}\")\n",
    "print(f\"Deep Learning Model Test R2:  {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b272d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 45210.4023 - rmse: 50244.6602 - val_loss: 13965.2422 - val_rmse: 17165.2246\n",
      "Epoch 2/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 14545.6221 - rmse: 17983.9297 - val_loss: 12836.2715 - val_rmse: 15801.0684\n",
      "Epoch 3/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13825.2002 - rmse: 17147.6270 - val_loss: 12658.9424 - val_rmse: 15636.1982\n",
      "Epoch 4/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13647.8730 - rmse: 16950.6758 - val_loss: 12601.7754 - val_rmse: 15564.3750\n",
      "Epoch 5/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13643.6299 - rmse: 16970.7559 - val_loss: 12588.7979 - val_rmse: 15570.9746\n",
      "Epoch 6/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13549.7646 - rmse: 16837.3496 - val_loss: 12569.0176 - val_rmse: 15546.0098\n",
      "Epoch 7/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13492.8594 - rmse: 16793.4609 - val_loss: 12554.7510 - val_rmse: 15550.1670\n",
      "Epoch 8/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13523.5029 - rmse: 16843.1445 - val_loss: 12548.2402 - val_rmse: 15509.9248\n",
      "Epoch 9/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13513.2041 - rmse: 16821.8535 - val_loss: 12533.8662 - val_rmse: 15499.7510\n",
      "Epoch 10/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13485.7344 - rmse: 16804.5469 - val_loss: 12534.3965 - val_rmse: 15495.4219\n",
      "Epoch 11/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13532.9287 - rmse: 16812.9434 - val_loss: 12537.3369 - val_rmse: 15511.3271\n",
      "Epoch 12/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13622.7148 - rmse: 16973.0527 - val_loss: 12519.6299 - val_rmse: 15487.9463\n",
      "Epoch 13/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13517.7148 - rmse: 16868.8926 - val_loss: 12527.8311 - val_rmse: 15492.2852\n",
      "Epoch 14/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13461.9775 - rmse: 16765.2461 - val_loss: 12516.2100 - val_rmse: 15481.2480\n",
      "Epoch 15/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13488.9590 - rmse: 16794.3633 - val_loss: 12533.3682 - val_rmse: 15526.9805\n",
      "Epoch 16/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13373.2617 - rmse: 16704.1270 - val_loss: 12541.4531 - val_rmse: 15501.2207\n",
      "Epoch 17/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13521.8105 - rmse: 16790.8125 - val_loss: 12531.8711 - val_rmse: 15550.2256\n",
      "Epoch 18/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13374.7275 - rmse: 16673.2441 - val_loss: 12543.7715 - val_rmse: 15516.8818\n",
      "Epoch 19/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13345.1377 - rmse: 16655.8516 - val_loss: 12528.4473 - val_rmse: 15499.0059\n",
      "Epoch 20/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13447.6152 - rmse: 16758.4102 - val_loss: 12514.9951 - val_rmse: 15496.8877\n",
      "Epoch 21/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13332.4902 - rmse: 16676.6719 - val_loss: 12515.0576 - val_rmse: 15507.4668\n",
      "Epoch 22/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13413.1436 - rmse: 16718.9180 - val_loss: 12511.8701 - val_rmse: 15495.9375\n",
      "Epoch 23/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13481.3623 - rmse: 16818.9121 - val_loss: 12515.0352 - val_rmse: 15493.3115\n",
      "Epoch 24/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13427.7852 - rmse: 16743.0195 - val_loss: 12518.9238 - val_rmse: 15487.4092\n",
      "Epoch 25/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13461.0469 - rmse: 16752.5059 - val_loss: 12514.9980 - val_rmse: 15498.4482\n",
      "Epoch 26/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13395.7461 - rmse: 16680.8535 - val_loss: 12504.2930 - val_rmse: 15500.5029\n",
      "Epoch 27/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13458.0020 - rmse: 16752.9863 - val_loss: 12505.9902 - val_rmse: 15480.7861\n",
      "Epoch 28/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13318.1641 - rmse: 16682.6699 - val_loss: 12519.6660 - val_rmse: 15494.1758\n",
      "Epoch 29/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13445.4297 - rmse: 16740.6797 - val_loss: 12513.5195 - val_rmse: 15501.1660\n",
      "Epoch 30/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13511.8291 - rmse: 16790.7383 - val_loss: 12511.3125 - val_rmse: 15474.2227\n",
      "Epoch 31/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13406.5283 - rmse: 16717.9746 - val_loss: 12509.1025 - val_rmse: 15504.3232\n",
      "Epoch 32/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13415.4199 - rmse: 16709.5215 - val_loss: 12524.3027 - val_rmse: 15505.7158\n",
      "Epoch 33/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13380.9951 - rmse: 16667.8926 - val_loss: 12512.7041 - val_rmse: 15491.9688\n",
      "Epoch 34/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13489.9023 - rmse: 16799.2246 - val_loss: 12521.5293 - val_rmse: 15487.7412\n",
      "Epoch 35/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13466.6396 - rmse: 16791.8984 - val_loss: 12520.2109 - val_rmse: 15521.4639\n",
      "Epoch 36/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13409.5361 - rmse: 16689.5156 - val_loss: 12525.3682 - val_rmse: 15493.5244\n",
      "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step\n",
      "Deep Learning Model Test MAE:   12787.57\n",
      "Deep Learning Model Test R2:    0.219\n",
      "Deep Learning Model Test MAPE:  26.61%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "df = pd.read_csv('/Users/maximbortnik/Downloads/dataset_with_company_count_M.csv', sep=';', low_memory=False)\n",
    "\n",
    "TARGET = 'salary.amount'\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "numeric_feats = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_feats = [c for c in X.columns if c not in numeric_feats]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_feats),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_feats)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "n_features = X_train_proc.shape[1]\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(n_features,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1) \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    ")\n",
    "\n",
    "es = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_proc, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test_proc).flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2  = r2_score(y_test, y_pred)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    nonzero = np.where(np.abs(y_true) < 1e-8, 1e-8, np.abs(y_true))\n",
    "    return np.mean(np.abs((y_true - y_pred) / nonzero)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Deep Learning Model Test MAE:   {mae:.2f}\")\n",
    "print(f\"Deep Learning Model Test R2:    {r2:.3f}\")\n",
    "print(f\"Deep Learning Model Test MAPE:  {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40628503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 57771.2031 - rmse: 60459.4336 - val_loss: 57083.6680 - val_rmse: 59720.2734 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 57545.3125 - rmse: 60246.1172 - val_loss: 56439.6719 - val_rmse: 59108.2852 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 56755.3164 - rmse: 59487.1367 - val_loss: 55494.9141 - val_rmse: 58208.8359 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 55848.1875 - rmse: 58604.6719 - val_loss: 54300.7461 - val_rmse: 57069.3203 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 54560.4023 - rmse: 57396.9961 - val_loss: 52868.0781 - val_rmse: 55710.0664 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 53054.9766 - rmse: 55956.0195 - val_loss: 51205.6016 - val_rmse: 54133.4922 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 51220.2422 - rmse: 54263.7617 - val_loss: 49316.6836 - val_rmse: 52349.0547 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 49445.4219 - rmse: 52574.3945 - val_loss: 47204.0508 - val_rmse: 50358.3203 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 47009.8711 - rmse: 50261.6836 - val_loss: 44883.4648 - val_rmse: 48187.0547 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 44809.2617 - rmse: 48198.8750 - val_loss: 42333.9102 - val_rmse: 45818.9648 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 41973.1172 - rmse: 45566.4492 - val_loss: 39556.0977 - val_rmse: 43268.8047 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 39246.0977 - rmse: 43129.9688 - val_loss: 36634.1602 - val_rmse: 40551.0664 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 36337.3789 - rmse: 40354.8984 - val_loss: 33539.5781 - val_rmse: 37571.9297 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 33318.5586 - rmse: 37481.0508 - val_loss: 30310.7539 - val_rmse: 34526.1875 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 30212.9824 - rmse: 34573.5508 - val_loss: 27142.9961 - val_rmse: 31428.5703 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 26746.5625 - rmse: 31166.2773 - val_loss: 23939.3652 - val_rmse: 28252.7227 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 23732.2598 - rmse: 28188.3906 - val_loss: 20677.4004 - val_rmse: 24905.4629 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 20654.5059 - rmse: 24977.1621 - val_loss: 18101.1543 - val_rmse: 22201.0371 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 18004.7754 - rmse: 22128.5820 - val_loss: 15751.7246 - val_rmse: 19538.8965 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 16045.0615 - rmse: 19880.6484 - val_loss: 14199.0264 - val_rmse: 17696.1777 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 14536.0908 - rmse: 18071.8770 - val_loss: 13260.9355 - val_rmse: 16519.5000 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13901.9355 - rmse: 17225.9336 - val_loss: 12856.3525 - val_rmse: 15950.5146 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13433.1318 - rmse: 16601.1602 - val_loss: 12722.9180 - val_rmse: 15704.2881 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13195.3711 - rmse: 16324.6260 - val_loss: 12688.3730 - val_rmse: 15633.8447 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13276.3066 - rmse: 16397.2969 - val_loss: 12676.0234 - val_rmse: 15616.8682 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13226.0322 - rmse: 16318.3965 - val_loss: 12658.5186 - val_rmse: 15616.3418 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13249.5312 - rmse: 16379.7832 - val_loss: 12670.1553 - val_rmse: 15620.4277 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 13294.7012 - rmse: 16429.0605 - val_loss: 12677.7432 - val_rmse: 15670.8730 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13195.4434 - rmse: 16359.8779 - val_loss: 12672.8906 - val_rmse: 15653.2129 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13252.9102 - rmse: 16404.8633 - val_loss: 12676.0117 - val_rmse: 15698.6729 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13218.2725 - rmse: 16398.4590 - val_loss: 12661.7148 - val_rmse: 15636.1787 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13218.4756 - rmse: 16374.1797 - val_loss: 12648.6973 - val_rmse: 15611.5176 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13240.7432 - rmse: 16361.4365 - val_loss: 12660.4111 - val_rmse: 15618.6523 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13186.2666 - rmse: 16309.3213 - val_loss: 12643.3848 - val_rmse: 15620.2480 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13180.2295 - rmse: 16309.2510 - val_loss: 12664.8311 - val_rmse: 15611.7695 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13220.7920 - rmse: 16354.2822 - val_loss: 12646.6807 - val_rmse: 15643.8711 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13114.3799 - rmse: 16232.0996 - val_loss: 12666.7764 - val_rmse: 15628.9385 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13139.0293 - rmse: 16252.1299 - val_loss: 12660.1035 - val_rmse: 15652.8066 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13173.3535 - rmse: 16334.5459 - val_loss: 12648.5938 - val_rmse: 15623.4561 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13147.7861 - rmse: 16329.3330 - val_loss: 12639.3936 - val_rmse: 15619.9043 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13095.1162 - rmse: 16252.0195 - val_loss: 12636.1611 - val_rmse: 15608.1992 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13129.6689 - rmse: 16282.6836 - val_loss: 12631.6953 - val_rmse: 15640.4512 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13254.2334 - rmse: 16390.2812 - val_loss: 12635.7051 - val_rmse: 15622.0576 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13150.9727 - rmse: 16301.5049 - val_loss: 12637.9629 - val_rmse: 15608.0098 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13141.1953 - rmse: 16342.1289 - val_loss: 12627.9990 - val_rmse: 15593.9863 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13049.6797 - rmse: 16174.6152 - val_loss: 12636.1689 - val_rmse: 15615.6846 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13126.9199 - rmse: 16271.2725 - val_loss: 12636.4912 - val_rmse: 15612.3516 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13089.0273 - rmse: 16265.3926 - val_loss: 12643.3018 - val_rmse: 15627.3906 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13099.7109 - rmse: 16236.6602 - val_loss: 12645.6182 - val_rmse: 15613.4170 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13158.2109 - rmse: 16282.6230 - val_loss: 12643.0762 - val_rmse: 15621.0420 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13098.7656 - rmse: 16253.1074 - val_loss: 12639.6631 - val_rmse: 15634.2324 - learning_rate: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13150.7832 - rmse: 16311.1875 - val_loss: 12638.1016 - val_rmse: 15609.8369 - learning_rate: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13114.1436 - rmse: 16274.3926 - val_loss: 12639.3076 - val_rmse: 15612.2764 - learning_rate: 1.2500e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13168.6768 - rmse: 16318.5801 - val_loss: 12637.1436 - val_rmse: 15610.6924 - learning_rate: 1.2500e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m1270/1270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 13095.8691 - rmse: 16210.8730 - val_loss: 12634.9023 - val_rmse: 15608.8877 - learning_rate: 1.2500e-04\n",
      "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step\n",
      "MAE:   12943.87\n",
      "R2:    0.202\n",
      "MAPE:  26.59%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "df = pd.read_csv('/Users/maximbortnik/Downloads/dataset_with_company_count_M.csv', sep=';', low_memory=False)\n",
    "\n",
    "\n",
    "TARGET = 'salary.amount'\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "def smooth_target_encoding(X_tr, y_tr, X_te, col, alpha=10):\n",
    "    \"\"\"\n",
    "    X_tr, y_tr — train; X_te — test\n",
    "    col — имя категориального столбца\n",
    "    alpha — параметр сглаживания\n",
    "    \"\"\"\n",
    "    mu = y_tr.mean()\n",
    "    stats = y_tr.groupby(X_tr[col]).agg(['mean','count']).rename(\n",
    "        columns={'mean':'mean_target','count':'count'}\n",
    "    )\n",
    "    stats['smooth'] = (stats['count']*stats['mean_target'] + alpha*mu) / (stats['count'] + alpha)\n",
    "    mapping = stats['smooth'].to_dict()\n",
    "    X_tr[col + '_te'] = X_tr[col].map(mapping).fillna(mu)\n",
    "    X_te[col + '_te'] = X_te[col].map(mapping).fillna(mu)\n",
    "    return X_tr, X_te\n",
    "\n",
    "for cat in ['area_orig', 'vacancy_type']:\n",
    "    X_train, X_test = smooth_target_encoding(X_train, y_train, X_test, cat, alpha=10)\n",
    "\n",
    "X_train = X_train.drop(columns=['area_orig','vacancy_type'])\n",
    "X_test  = X_test.drop(columns=['area_orig','vacancy_type'])\n",
    "\n",
    "numeric_feats = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_feats)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "n_features = X_train_proc.shape[1]\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(n_features,)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    ")\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "model.fit(\n",
    "    X_train_proc, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[es, rlr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test_proc).flatten()\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denom = np.where(np.abs(y_true)<1e-8,1e-8,np.abs(y_true))\n",
    "    return np.mean(np.abs((y_true-y_pred)/denom))*100\n",
    "\n",
    "mape_val = mape(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE:   {mae:.2f}\")\n",
    "print(f\"R2:    {r2:.3f}\")\n",
    "print(f\"MAPE:  {mape_val:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8543b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 45757.2227 - rmse: 49899.5078 - val_loss: 12765.3047 - val_rmse: 15657.4834\n",
      "Epoch 2/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13224.4336 - rmse: 16206.4287 - val_loss: 11524.9736 - val_rmse: 14070.2539\n",
      "Epoch 3/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12413.6846 - rmse: 15269.2793 - val_loss: 11295.4004 - val_rmse: 13850.6436\n",
      "Epoch 4/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12308.4766 - rmse: 15168.8418 - val_loss: 11230.4053 - val_rmse: 13776.3799\n",
      "Epoch 5/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12190.2471 - rmse: 15073.0459 - val_loss: 11215.5615 - val_rmse: 13779.6631\n",
      "Epoch 6/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12255.6084 - rmse: 15085.7539 - val_loss: 11183.9688 - val_rmse: 13723.2607\n",
      "Epoch 7/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12167.1289 - rmse: 15049.4941 - val_loss: 11146.1855 - val_rmse: 13700.0439\n",
      "Epoch 8/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12146.7539 - rmse: 15019.2188 - val_loss: 11144.7207 - val_rmse: 13659.1465\n",
      "Epoch 9/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12121.5322 - rmse: 14997.0928 - val_loss: 11140.5117 - val_rmse: 13625.6377\n",
      "Epoch 10/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12173.6953 - rmse: 15035.3096 - val_loss: 11166.2275 - val_rmse: 13701.3008\n",
      "Epoch 11/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12162.9648 - rmse: 14974.7217 - val_loss: 11138.5918 - val_rmse: 13621.1387\n",
      "Epoch 12/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12171.4199 - rmse: 15071.6035 - val_loss: 11124.7080 - val_rmse: 13648.6709\n",
      "Epoch 13/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12063.2061 - rmse: 14921.6924 - val_loss: 11164.9961 - val_rmse: 13732.8486\n",
      "Epoch 14/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12160.8955 - rmse: 15002.4561 - val_loss: 11128.6357 - val_rmse: 13628.7168\n",
      "Epoch 15/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12182.4932 - rmse: 15002.7783 - val_loss: 11108.5703 - val_rmse: 13642.6445\n",
      "Epoch 16/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12120.7900 - rmse: 15003.3721 - val_loss: 11096.5508 - val_rmse: 13607.0654\n",
      "Epoch 17/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12163.2754 - rmse: 15000.5547 - val_loss: 11124.5449 - val_rmse: 13676.6445\n",
      "Epoch 18/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12064.0732 - rmse: 14899.0586 - val_loss: 11108.3477 - val_rmse: 13583.1963\n",
      "Epoch 19/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12073.8779 - rmse: 14891.6602 - val_loss: 11125.8633 - val_rmse: 13712.1523\n",
      "Epoch 20/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12032.5244 - rmse: 14900.4053 - val_loss: 11122.8428 - val_rmse: 13685.1641\n",
      "Epoch 21/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 11955.6699 - rmse: 14794.1504 - val_loss: 11117.4023 - val_rmse: 13666.8193\n",
      "Epoch 22/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12025.1689 - rmse: 14859.6191 - val_loss: 11087.3828 - val_rmse: 13603.1729\n",
      "Epoch 23/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12038.2217 - rmse: 14846.7461 - val_loss: 11112.6836 - val_rmse: 13638.0576\n",
      "Epoch 24/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12000.2764 - rmse: 14853.3848 - val_loss: 11084.7500 - val_rmse: 13599.5557\n",
      "Epoch 25/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12061.3789 - rmse: 14914.0547 - val_loss: 11097.5527 - val_rmse: 13601.7627\n",
      "Epoch 26/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12070.4482 - rmse: 14932.7695 - val_loss: 11101.6094 - val_rmse: 13585.8740\n",
      "Epoch 27/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12001.1729 - rmse: 14839.6426 - val_loss: 11099.4785 - val_rmse: 13640.9717\n",
      "Epoch 28/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 11983.7959 - rmse: 14812.7549 - val_loss: 11143.9971 - val_rmse: 13725.8828\n",
      "Epoch 29/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12053.7666 - rmse: 14927.5518 - val_loss: 11109.0762 - val_rmse: 13624.3848\n",
      "Epoch 30/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12048.6152 - rmse: 14923.8877 - val_loss: 11130.1387 - val_rmse: 13702.2334\n",
      "Epoch 31/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12008.2207 - rmse: 14878.9180 - val_loss: 11086.1270 - val_rmse: 13613.3281\n",
      "Epoch 32/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 11985.3389 - rmse: 14832.2627 - val_loss: 11113.6357 - val_rmse: 13632.3408\n",
      "Epoch 33/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 12057.5684 - rmse: 14901.5371 - val_loss: 11104.6631 - val_rmse: 13659.2695\n",
      "Epoch 34/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 11973.8252 - rmse: 14783.2461 - val_loss: 11103.3936 - val_rmse: 13633.5166\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step\n",
      "Deep Learning Model Test MAE:   11153.99\n",
      "Deep Learning Model Test R2:    0.174\n",
      "Deep Learning Model Test MAPE:  21.92%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "df = pd.read_csv('/Users/maximbortnik/Downloads/dataset_with_company_count_M.csv', sep=';', low_memory=False)\n",
    "df = df[(df['salary.amount'] >= 30000) & (df['salary.amount'] <= 80000)]\n",
    "TARGET = 'salary.amount'\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "numeric_feats = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_feats = [c for c in X.columns if c not in numeric_feats]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_feats),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_feats)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "n_features = X_train_proc.shape[1]\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(n_features,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)  \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    ")\n",
    "\n",
    "es = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_proc, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test_proc).flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2  = r2_score(y_test, y_pred)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    nonzero = np.where(np.abs(y_true) < 1e-8, 1e-8, np.abs(y_true))\n",
    "    return np.mean(np.abs((y_true - y_pred) / nonzero)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Deep Learning Model Test MAE:   {mae:.2f}\")\n",
    "print(f\"Deep Learning Model Test R2:    {r2:.3f}\")\n",
    "print(f\"Deep Learning Model Test MAPE:  {mape:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539b3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n",
      "MAE:   11063.59\n",
      "R2:    0.186\n",
      "MAPE:  21.68%\n",
      "ME:    -446.63\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('/Users/maximbortnik/Downloads/dataset_with_company_count_M.csv', sep=';', low_memory=False)\n",
    "df = df[(df['salary.amount'] >= 30000) & (df['salary.amount'] <= 80000)]\n",
    "\n",
    "TARGET = 'salary.amount'\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "numeric_feats = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_feats = [c for c in X.columns if c not in numeric_feats]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_feats),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_feats)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "n_features = X_train_proc.shape[1]\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(n_features,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    ")\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(X_train_proc, y_train, validation_split=0.2, epochs=100, batch_size=32, callbacks=[es], verbose=0)\n",
    "\n",
    "y_pred = model.predict(X_test_proc).flatten()\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "mean_error = np.mean(y_pred - y_test)  \n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    denom = np.where(np.abs(y_true) < 1e-8, 1e-8, np.abs(y_true))\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE:   {mae:.2f}\")\n",
    "print(f\"R2:    {r2:.3f}\")\n",
    "print(f\"MAPE:  {mape:.2f}%\")\n",
    "print(f\"ME:    {mean_error:.2f}\")\n",
    "\n",
    "residuals = y_pred - y_test.values\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(y_test, residuals, alpha=0.5)\n",
    "plt.hlines(0, xmin=y_test.min(), xmax=y_test.max(), colors='r', linestyles='dashed')\n",
    "plt.xlabel('True Salary')\n",
    "plt.ylabel('Residual (Predicted - True)')\n",
    "plt.title('Residuals Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6434f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5.7170 - rmse: 6.8932 - val_loss: 0.3291 - val_rmse: 0.3986 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9044 - rmse: 1.2992 - val_loss: 0.3267 - val_rmse: 0.3584 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.7586 - rmse: 1.0261 - val_loss: 0.3252 - val_rmse: 0.3539 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6897 - rmse: 0.8972 - val_loss: 0.2707 - val_rmse: 0.2939 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6419 - rmse: 0.8066 - val_loss: 0.2548 - val_rmse: 0.2734 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5892 - rmse: 0.7227 - val_loss: 0.2362 - val_rmse: 0.2643 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5597 - rmse: 0.6811 - val_loss: 0.2444 - val_rmse: 0.2733 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5299 - rmse: 0.6454 - val_loss: 0.2275 - val_rmse: 0.2592 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5065 - rmse: 0.6167 - val_loss: 0.2273 - val_rmse: 0.2603 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4877 - rmse: 0.5988 - val_loss: 0.2369 - val_rmse: 0.2724 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4685 - rmse: 0.5786 - val_loss: 0.2192 - val_rmse: 0.2586 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4556 - rmse: 0.5647 - val_loss: 0.2148 - val_rmse: 0.2565 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4359 - rmse: 0.5412 - val_loss: 0.2135 - val_rmse: 0.2546 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.4298 - rmse: 0.5335 - val_loss: 0.2143 - val_rmse: 0.2671 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4189 - rmse: 0.5188 - val_loss: 0.2390 - val_rmse: 0.2791 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4126 - rmse: 0.5107 - val_loss: 0.2129 - val_rmse: 0.2550 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3974 - rmse: 0.4931 - val_loss: 0.2359 - val_rmse: 0.2799 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3884 - rmse: 0.4802 - val_loss: 0.2547 - val_rmse: 0.2950 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3764 - rmse: 0.4677 - val_loss: 0.2399 - val_rmse: 0.2805 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.3677 - rmse: 0.4552 - val_loss: 0.2074 - val_rmse: 0.2567 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.3636 - rmse: 0.4504 - val_loss: 0.2215 - val_rmse: 0.2617 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.3540 - rmse: 0.4400 - val_loss: 0.2162 - val_rmse: 0.2579 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3386 - rmse: 0.4188 - val_loss: 0.2173 - val_rmse: 0.2584 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3383 - rmse: 0.4177 - val_loss: 0.2115 - val_rmse: 0.2563 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3266 - rmse: 0.4047 - val_loss: 0.2081 - val_rmse: 0.2534 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.3147 - rmse: 0.3905 - val_loss: 0.2063 - val_rmse: 0.2525 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3105 - rmse: 0.3859 - val_loss: 0.2115 - val_rmse: 0.2539 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.3094 - rmse: 0.3840 - val_loss: 0.2157 - val_rmse: 0.2573 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3055 - rmse: 0.3786 - val_loss: 0.2080 - val_rmse: 0.2526 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3015 - rmse: 0.3749 - val_loss: 0.2059 - val_rmse: 0.2507 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2921 - rmse: 0.3645 - val_loss: 0.2048 - val_rmse: 0.2511 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2921 - rmse: 0.3631 - val_loss: 0.2037 - val_rmse: 0.2518 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2878 - rmse: 0.3578 - val_loss: 0.2033 - val_rmse: 0.2538 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2875 - rmse: 0.3580 - val_loss: 0.2083 - val_rmse: 0.2530 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2839 - rmse: 0.3527 - val_loss: 0.2016 - val_rmse: 0.2522 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2797 - rmse: 0.3482 - val_loss: 0.2034 - val_rmse: 0.2516 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2751 - rmse: 0.3429 - val_loss: 0.2051 - val_rmse: 0.2507 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2715 - rmse: 0.3382 - val_loss: 0.2088 - val_rmse: 0.2527 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2693 - rmse: 0.3353 - val_loss: 0.2017 - val_rmse: 0.2523 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2663 - rmse: 0.3322 - val_loss: 0.2022 - val_rmse: 0.2513 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2632 - rmse: 0.3290 - val_loss: 0.2044 - val_rmse: 0.2500 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2622 - rmse: 0.3267 - val_loss: 0.2018 - val_rmse: 0.2502 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2639 - rmse: 0.3293 - val_loss: 0.2004 - val_rmse: 0.2499 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2591 - rmse: 0.3239 - val_loss: 0.2041 - val_rmse: 0.2497 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2552 - rmse: 0.3180 - val_loss: 0.2024 - val_rmse: 0.2492 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2587 - rmse: 0.3230 - val_loss: 0.2029 - val_rmse: 0.2492 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2546 - rmse: 0.3186 - val_loss: 0.2009 - val_rmse: 0.2491 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2542 - rmse: 0.3165 - val_loss: 0.2010 - val_rmse: 0.2499 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2524 - rmse: 0.3160 - val_loss: 0.2021 - val_rmse: 0.2489 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2505 - rmse: 0.3141 - val_loss: 0.2011 - val_rmse: 0.2495 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2483 - rmse: 0.3121 - val_loss: 0.2026 - val_rmse: 0.2489 - learning_rate: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2509 - rmse: 0.3132 - val_loss: 0.2001 - val_rmse: 0.2496 - learning_rate: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2478 - rmse: 0.3101 - val_loss: 0.2007 - val_rmse: 0.2497 - learning_rate: 1.2500e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2488 - rmse: 0.3111 - val_loss: 0.1997 - val_rmse: 0.2496 - learning_rate: 1.2500e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2472 - rmse: 0.3095 - val_loss: 0.2017 - val_rmse: 0.2485 - learning_rate: 1.2500e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2483 - rmse: 0.3105 - val_loss: 0.2004 - val_rmse: 0.2489 - learning_rate: 1.2500e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2480 - rmse: 0.3098 - val_loss: 0.2022 - val_rmse: 0.2485 - learning_rate: 1.2500e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2459 - rmse: 0.3079 - val_loss: 0.2006 - val_rmse: 0.2492 - learning_rate: 1.2500e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2465 - rmse: 0.3081 - val_loss: 0.2020 - val_rmse: 0.2491 - learning_rate: 1.2500e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2451 - rmse: 0.3068 - val_loss: 0.2003 - val_rmse: 0.2493 - learning_rate: 6.2500e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2452 - rmse: 0.3069 - val_loss: 0.2004 - val_rmse: 0.2490 - learning_rate: 6.2500e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2436 - rmse: 0.3047 - val_loss: 0.1999 - val_rmse: 0.2497 - learning_rate: 6.2500e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2444 - rmse: 0.3063 - val_loss: 0.2000 - val_rmse: 0.2492 - learning_rate: 6.2500e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2436 - rmse: 0.3047 - val_loss: 0.1997 - val_rmse: 0.2495 - learning_rate: 6.2500e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2398 - rmse: 0.3012 - val_loss: 0.1998 - val_rmse: 0.2488 - learning_rate: 3.1250e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2394 - rmse: 0.3005 - val_loss: 0.2007 - val_rmse: 0.2488 - learning_rate: 3.1250e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2416 - rmse: 0.3016 - val_loss: 0.1995 - val_rmse: 0.2490 - learning_rate: 3.1250e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2429 - rmse: 0.3047 - val_loss: 0.1998 - val_rmse: 0.2489 - learning_rate: 3.1250e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2416 - rmse: 0.3021 - val_loss: 0.2000 - val_rmse: 0.2490 - learning_rate: 3.1250e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2399 - rmse: 0.3004 - val_loss: 0.1996 - val_rmse: 0.2494 - learning_rate: 3.1250e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2429 - rmse: 0.3040 - val_loss: 0.1995 - val_rmse: 0.2496 - learning_rate: 3.1250e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2399 - rmse: 0.3010 - val_loss: 0.1996 - val_rmse: 0.2495 - learning_rate: 3.1250e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2409 - rmse: 0.3024 - val_loss: 0.1996 - val_rmse: 0.2497 - learning_rate: 1.5625e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2416 - rmse: 0.3029 - val_loss: 0.1998 - val_rmse: 0.2492 - learning_rate: 1.5625e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2415 - rmse: 0.3019 - val_loss: 0.2002 - val_rmse: 0.2488 - learning_rate: 1.5625e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2399 - rmse: 0.3000 - val_loss: 0.1995 - val_rmse: 0.2494 - learning_rate: 1.5625e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2401 - rmse: 0.3010 - val_loss: 0.1998 - val_rmse: 0.2491 - learning_rate: 1.5625e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2402 - rmse: 0.3002 - val_loss: 0.2002 - val_rmse: 0.2491 - learning_rate: 7.8125e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2394 - rmse: 0.2994 - val_loss: 0.1995 - val_rmse: 0.2494 - learning_rate: 7.8125e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2390 - rmse: 0.3000 - val_loss: 0.1999 - val_rmse: 0.2491 - learning_rate: 7.8125e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2388 - rmse: 0.2995 - val_loss: 0.2001 - val_rmse: 0.2493 - learning_rate: 7.8125e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2423 - rmse: 0.3034 - val_loss: 0.2001 - val_rmse: 0.2492 - learning_rate: 7.8125e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2381 - rmse: 0.2993 - val_loss: 0.1998 - val_rmse: 0.2495 - learning_rate: 3.9063e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2390 - rmse: 0.2992 - val_loss: 0.1999 - val_rmse: 0.2493 - learning_rate: 3.9063e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2405 - rmse: 0.3010 - val_loss: 0.2000 - val_rmse: 0.2494 - learning_rate: 3.9063e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2419 - rmse: 0.3027 - val_loss: 0.1997 - val_rmse: 0.2494 - learning_rate: 3.9063e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2399 - rmse: 0.3016 - val_loss: 0.2000 - val_rmse: 0.2492 - learning_rate: 3.9063e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2371 - rmse: 0.2973 - val_loss: 0.2003 - val_rmse: 0.2491 - learning_rate: 1.9531e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2383 - rmse: 0.2999 - val_loss: 0.2003 - val_rmse: 0.2492 - learning_rate: 1.9531e-06\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step\n",
      "Log-transformed DL Model Test MAE:   10882.22\n",
      "Log-transformed DL Model Test R2:    0.212\n",
      "Log-transformed DL Model Test MAPE:  21.22%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "df = pd.read_csv('/Users/maximbortnik/Downloads/dataset_with_company_count_M.csv', sep=';', low_memory=False)\n",
    "df = df[(df['salary.amount'] >= 30000) & (df['salary.amount'] <= 80000)]\n",
    "\n",
    "TARGET = 'salary.amount'\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log  = np.log1p(y_test)\n",
    "\n",
    "sample_weights = y_train_log / np.mean(y_train_log)\n",
    "\n",
    "numeric_feats = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_feats = [c for c in X.columns if c not in numeric_feats]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_feats),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_feats)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "n_features = X_train_proc.shape[1]\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(n_features,)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)  \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    ")\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "history = model.fit(\n",
    "    X_train_proc, y_train_log,\n",
    "    sample_weight=sample_weights,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[es, rlr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred_log = model.predict(X_test_proc).flatten()\n",
    "y_pred     = np.expm1(y_pred_log)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2  = r2_score(y_test, y_pred)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    denom = np.where(np.abs(y_true) < 1e-8, 1e-8, np.abs(y_true))\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Log-transformed DL Model Test MAE:   {mae:.2f}\")\n",
    "print(f\"Log-transformed DL Model Test R2:    {r2:.3f}\")\n",
    "print(f\"Log-transformed DL Model Test MAPE:  {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e5293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 5.5281 - rmse: 6.7118 - val_loss: 0.3405 - val_rmse: 0.3738 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.9101 - rmse: 1.2219 - val_loss: 0.3491 - val_rmse: 0.3716 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.7516 - rmse: 0.9829 - val_loss: 0.2743 - val_rmse: 0.2919 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6722 - rmse: 0.8517 - val_loss: 0.2595 - val_rmse: 0.2784 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6182 - rmse: 0.7596 - val_loss: 0.2699 - val_rmse: 0.2909 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5798 - rmse: 0.7009 - val_loss: 0.2499 - val_rmse: 0.2766 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5411 - rmse: 0.6567 - val_loss: 0.2664 - val_rmse: 0.3016 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5215 - rmse: 0.6311 - val_loss: 0.2368 - val_rmse: 0.2732 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.5018 - rmse: 0.6146 - val_loss: 0.2688 - val_rmse: 0.3049 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.4849 - rmse: 0.5939 - val_loss: 0.2364 - val_rmse: 0.2749 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4659 - rmse: 0.5756 - val_loss: 0.2291 - val_rmse: 0.2691 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4544 - rmse: 0.5597 - val_loss: 0.2231 - val_rmse: 0.2704 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4356 - rmse: 0.5395 - val_loss: 0.2266 - val_rmse: 0.2691 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4319 - rmse: 0.5330 - val_loss: 0.2298 - val_rmse: 0.2723 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4123 - rmse: 0.5103 - val_loss: 0.2235 - val_rmse: 0.2663 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.4056 - rmse: 0.5046 - val_loss: 0.2242 - val_rmse: 0.2701 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3966 - rmse: 0.4902 - val_loss: 0.2240 - val_rmse: 0.2677 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3882 - rmse: 0.4828 - val_loss: 0.2213 - val_rmse: 0.2649 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3764 - rmse: 0.4680 - val_loss: 0.2168 - val_rmse: 0.2650 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3719 - rmse: 0.4641 - val_loss: 0.2199 - val_rmse: 0.2653 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3669 - rmse: 0.4562 - val_loss: 0.2229 - val_rmse: 0.2668 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3627 - rmse: 0.4510 - val_loss: 0.2149 - val_rmse: 0.2635 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3567 - rmse: 0.4440 - val_loss: 0.2199 - val_rmse: 0.2643 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3538 - rmse: 0.4389 - val_loss: 0.2182 - val_rmse: 0.2632 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3486 - rmse: 0.4323 - val_loss: 0.2157 - val_rmse: 0.2630 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3413 - rmse: 0.4245 - val_loss: 0.2138 - val_rmse: 0.2632 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3371 - rmse: 0.4187 - val_loss: 0.2162 - val_rmse: 0.2638 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3320 - rmse: 0.4139 - val_loss: 0.2143 - val_rmse: 0.2650 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3297 - rmse: 0.4094 - val_loss: 0.2159 - val_rmse: 0.2626 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3261 - rmse: 0.4055 - val_loss: 0.2126 - val_rmse: 0.2651 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3238 - rmse: 0.4030 - val_loss: 0.2202 - val_rmse: 0.2663 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3152 - rmse: 0.3918 - val_loss: 0.2136 - val_rmse: 0.2626 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3136 - rmse: 0.3883 - val_loss: 0.2133 - val_rmse: 0.2641 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3087 - rmse: 0.3837 - val_loss: 0.2153 - val_rmse: 0.2626 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3074 - rmse: 0.3817 - val_loss: 0.2151 - val_rmse: 0.2614 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2989 - rmse: 0.3726 - val_loss: 0.2119 - val_rmse: 0.2608 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2996 - rmse: 0.3737 - val_loss: 0.2111 - val_rmse: 0.2622 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2939 - rmse: 0.3668 - val_loss: 0.2109 - val_rmse: 0.2619 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2921 - rmse: 0.3638 - val_loss: 0.2112 - val_rmse: 0.2606 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2937 - rmse: 0.3662 - val_loss: 0.2133 - val_rmse: 0.2610 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2920 - rmse: 0.3636 - val_loss: 0.2155 - val_rmse: 0.2618 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2848 - rmse: 0.3551 - val_loss: 0.2126 - val_rmse: 0.2605 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2834 - rmse: 0.3538 - val_loss: 0.2101 - val_rmse: 0.2618 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2861 - rmse: 0.3565 - val_loss: 0.2106 - val_rmse: 0.2614 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2821 - rmse: 0.3526 - val_loss: 0.2103 - val_rmse: 0.2638 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2802 - rmse: 0.3506 - val_loss: 0.2125 - val_rmse: 0.2629 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2778 - rmse: 0.3464 - val_loss: 0.2117 - val_rmse: 0.2609 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2762 - rmse: 0.3455 - val_loss: 0.2113 - val_rmse: 0.2603 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2754 - rmse: 0.3443 - val_loss: 0.2103 - val_rmse: 0.2604 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2731 - rmse: 0.3419 - val_loss: 0.2129 - val_rmse: 0.2605 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2737 - rmse: 0.3416 - val_loss: 0.2096 - val_rmse: 0.2621 - learning_rate: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2724 - rmse: 0.3398 - val_loss: 0.2111 - val_rmse: 0.2607 - learning_rate: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2720 - rmse: 0.3396 - val_loss: 0.2126 - val_rmse: 0.2605 - learning_rate: 1.2500e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2703 - rmse: 0.3383 - val_loss: 0.2112 - val_rmse: 0.2605 - learning_rate: 1.2500e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2702 - rmse: 0.3372 - val_loss: 0.2152 - val_rmse: 0.2619 - learning_rate: 1.2500e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2703 - rmse: 0.3371 - val_loss: 0.2133 - val_rmse: 0.2619 - learning_rate: 1.2500e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2671 - rmse: 0.3340 - val_loss: 0.2112 - val_rmse: 0.2603 - learning_rate: 6.2500e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2656 - rmse: 0.3328 - val_loss: 0.2108 - val_rmse: 0.2608 - learning_rate: 6.2500e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2655 - rmse: 0.3321 - val_loss: 0.2099 - val_rmse: 0.2609 - learning_rate: 6.2500e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2646 - rmse: 0.3310 - val_loss: 0.2116 - val_rmse: 0.2604 - learning_rate: 6.2500e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2651 - rmse: 0.3312 - val_loss: 0.2111 - val_rmse: 0.2606 - learning_rate: 6.2500e-05\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step\n",
      "Log-transformed DL Model Test MAE:   11882.58\n",
      "Log-transformed DL Model Test R2:    0.236\n",
      "Log-transformed DL Model Test MAPE:  22.56%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "df = pd.read_csv('/Users/maximbortnik/Downloads/dataset_with_company_count_M.csv', sep=';', low_memory=False)\n",
    "df = df[(df['salary.amount'] >= 30000) & (df['salary.amount'] <= 90000)]\n",
    "\n",
    "TARGET = 'salary.amount'\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log  = np.log1p(y_test)\n",
    "\n",
    "sample_weights = y_train_log / np.mean(y_train_log)\n",
    "\n",
    "numeric_feats = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_feats = [c for c in X.columns if c not in numeric_feats]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_feats),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_feats)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "n_features = X_train_proc.shape[1]\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(n_features,)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1) \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    ")\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "history = model.fit(\n",
    "    X_train_proc, y_train_log,\n",
    "    sample_weight=sample_weights,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[es, rlr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred_log = model.predict(X_test_proc).flatten()\n",
    "y_pred     = np.expm1(y_pred_log)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2  = r2_score(y_test, y_pred)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    denom = np.where(np.abs(y_true) < 1e-8, 1e-8, np.abs(y_true))\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Log-transformed DL Model Test MAE:   {mae:.2f}\")\n",
    "print(f\"Log-transformed DL Model Test R2:    {r2:.3f}\")\n",
    "print(f\"Log-transformed DL Model Test MAPE:  {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101ead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Threshold 0.06: 23 features ===\n",
      " MAE = 12331.66\n",
      " R2 = 0.14\n",
      "\n",
      "=== Threshold 0.08: 20 features ===\n",
      " MAE = 12354.02\n",
      " R2 = 0.14\n",
      "\n",
      "=== Threshold 0.10: 20 features ===\n",
      " MAE = 12354.02\n",
      " R2 = 0.14\n",
      "\n",
      "=== Threshold 0.15: 15 features ===\n",
      " MAE = 12545.67\n",
      " R2 = 0.14\n",
      "\n",
      "=== Threshold 0.18: 12 features ===\n",
      " MAE = 12588.01\n",
      " R2 = 0.14\n",
      "\n",
      "=== Threshold 0.20: 8 features ===\n",
      " MAE = 13121.84\n",
      " R2 = 0.14\n",
      "\n",
      "=== Threshold 0.22: 7 features ===\n",
      " MAE = 13116.84\n",
      " R2 = 0.14\n",
      "\n",
      "=== Threshold 0.25: 0 features ===\n",
      " MAE = 13815.66\n",
      " R2 = 0.14\n",
      "\n",
      "📊 Результаты:\n",
      "   threshold  n_features                                        best_params  \\\n",
      "0       0.06          24  {'mdl__learning_rate': 0.10335257864959599, 'm...   \n",
      "1       0.08          21  {'mdl__learning_rate': 0.11495493205167782, 'm...   \n",
      "2       0.10          21  {'mdl__learning_rate': 0.11495493205167782, 'm...   \n",
      "3       0.15          16  {'mdl__learning_rate': 0.10335257864959599, 'm...   \n",
      "4       0.18          13  {'mdl__learning_rate': 0.13199933155652419, 'm...   \n",
      "5       0.20           9  {'mdl__learning_rate': 0.13199933155652419, 'm...   \n",
      "6       0.22           8  {'mdl__learning_rate': 0.15639878836228102, 'm...   \n",
      "7       0.25           1  {'mdl__learning_rate': 0.14606150771755597, 'm...   \n",
      "\n",
      "       test_mae  \n",
      "0  12331.657227  \n",
      "1  12354.021104  \n",
      "2  12354.021104  \n",
      "3  12545.671511  \n",
      "4  12588.009524  \n",
      "5  13121.840468  \n",
      "6  13116.838728  \n",
      "7  13815.659322  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "df = pd.read_csv('/Users/maximbortnik/Downloads/dataset_with_company_count_M.csv', sep=';', low_memory=False)\n",
    "df = df[(df['salary.amount'] >= 30000) & (df['salary.amount'] <= 90000)]\n",
    "X = df.drop('salary.amount', axis=1)\n",
    "y = df['salary.amount'].astype(float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_numeric = X_train.select_dtypes(include=[np.number])\n",
    "\n",
    "corr = pd.concat([X_train_numeric, y_train.rename('salary')], axis=1).corr()['salary'].abs().sort_values(ascending=False)\n",
    "\n",
    "thresholds = [0.06, 0.08, 0.1, 0.15, 0.18, 0.20, 0.22, 0.25]\n",
    "results = []\n",
    "\n",
    "cat_feat = 'vacancy_type'\n",
    "\n",
    "for thr in thresholds:\n",
    "    selected_feats = corr[corr.index != 'salary'][corr >= thr].index.tolist()\n",
    "    print(f\"\\n=== Threshold {thr:.2f}: {len(selected_feats)} features ===\")\n",
    "    \n",
    "    if cat_feat not in selected_feats:\n",
    "        selected_feats.append(cat_feat)\n",
    "\n",
    "    num_feats = [c for c in selected_feats if c != cat_feat and np.issubdtype(X_train[c].dtype, np.number)]\n",
    "    cat_feats = [cat_feat] if cat_feat in selected_feats else []\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), num_feats),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_feats)\n",
    "    ])\n",
    "\n",
    "    model = HistGradientBoostingRegressor(random_state=42)\n",
    "    pipe = Pipeline([\n",
    "        ('pre', preprocessor),\n",
    "        ('mdl', model)\n",
    "    ])\n",
    "\n",
    "    param_dist = {\n",
    "        'mdl__max_iter': randint(100, 300),\n",
    "        'mdl__learning_rate': uniform(0.01, 0.2),\n",
    "        'mdl__max_depth': randint(3, 10)\n",
    "    }\n",
    "\n",
    "    rs = RandomizedSearchCV(\n",
    "        pipe, param_dist,\n",
    "        n_iter=20, scoring='neg_mean_absolute_error',\n",
    "        cv=3, n_jobs=-1, random_state=42\n",
    "    )\n",
    "    rs.fit(X_train[selected_feats], y_train)\n",
    "\n",
    "    best_model = rs.best_estimator_\n",
    "    preds = best_model.predict(X_test[selected_feats])\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    results.append({\n",
    "        'threshold': thr,\n",
    "        'n_features': len(selected_feats),\n",
    "        'best_params': rs.best_params_,\n",
    "        'test_mae': mae\n",
    "    })\n",
    "    print(f\" MAE = {mae:.2f}\")\n",
    "    print(f\" R2 = {r2:.2f}\")\n",
    "\n",
    "print(\"\\n📊 Результаты:\")\n",
    "print(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88b7dbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vacancy_type</th>\n",
       "      <th>area_orig</th>\n",
       "      <th>age</th>\n",
       "      <th>gender.id</th>\n",
       "      <th>education.level.id</th>\n",
       "      <th>salary.amount</th>\n",
       "      <th>total_experience.months</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>inflation_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>natural_prirost_rozhd</th>\n",
       "      <th>mortality</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>percent_with_internet</th>\n",
       "      <th>migration_prirost</th>\n",
       "      <th>number_top_school</th>\n",
       "      <th>prirost_naselenia</th>\n",
       "      <th>percent_poor</th>\n",
       "      <th>rate_of_quality_life</th>\n",
       "      <th>exp_company_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Инсталлятор</td>\n",
       "      <td>Абинск</td>\n",
       "      <td>32.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>9.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>33903.0</td>\n",
       "      <td>68.3</td>\n",
       "      <td>62.54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.31</td>\n",
       "      <td>11.6</td>\n",
       "      <td>76.130</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Менеджер по поддержке продаж</td>\n",
       "      <td>Абинск</td>\n",
       "      <td>41.0</td>\n",
       "      <td>female</td>\n",
       "      <td>5.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>9.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>33903.0</td>\n",
       "      <td>68.3</td>\n",
       "      <td>62.54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.31</td>\n",
       "      <td>11.6</td>\n",
       "      <td>76.130</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Инсталлятор</td>\n",
       "      <td>Азов</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>9.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>32241.0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0.418252</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>13.9</td>\n",
       "      <td>68.296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Инсталлятор</td>\n",
       "      <td>Азов</td>\n",
       "      <td>24.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>9.51</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>32241.0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0.418252</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>13.9</td>\n",
       "      <td>68.296</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Инсталлятор</td>\n",
       "      <td>Аксай (Ростовская область)</td>\n",
       "      <td>39.0</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025</td>\n",
       "      <td>9.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>32241.0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0.418252</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>13.9</td>\n",
       "      <td>68.296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   vacancy_type                   area_orig   age gender.id  \\\n",
       "1                   Инсталлятор                      Абинск  32.0      male   \n",
       "2  Менеджер по поддержке продаж                      Абинск  41.0    female   \n",
       "3                   Инсталлятор                        Азов  50.0      male   \n",
       "4                   Инсталлятор                        Азов  24.0      male   \n",
       "5                   Инсталлятор  Аксай (Ростовская область)  39.0      male   \n",
       "\n",
       "   education.level.id  salary.amount  total_experience.months  month  year  \\\n",
       "1                 2.0        30000.0                     47.0      1  2025   \n",
       "2                 5.0        70000.0                    199.0      1  2025   \n",
       "3                 2.0        80000.0                    355.0      1  2025   \n",
       "4                 2.0        70000.0                     55.0     12  2024   \n",
       "5                 4.0        80000.0                    171.0      1  2025   \n",
       "\n",
       "   inflation_rate  ...  natural_prirost_rozhd mortality  median_salary  \\\n",
       "1            9.92  ...                   -0.5      12.5        33903.0   \n",
       "2            9.92  ...                   -0.5      12.5        33903.0   \n",
       "3            9.92  ...                   -3.1      13.4        32241.0   \n",
       "4            9.51  ...                   -3.1      13.4        32241.0   \n",
       "5            9.92  ...                   -3.1      13.4        32241.0   \n",
       "\n",
       "   percent_with_internet migration_prirost  number_top_school  \\\n",
       "1                   68.3             62.54           0.000000   \n",
       "2                   68.3             62.54           0.000000   \n",
       "3                   68.5              4.51           0.418252   \n",
       "4                   68.5              4.51           0.418252   \n",
       "5                   68.5              4.51           0.418252   \n",
       "\n",
       "   prirost_naselenia  percent_poor  rate_of_quality_life  exp_company_count  \n",
       "1              10.31          11.6                76.130                  2  \n",
       "2              10.31          11.6                76.130                  6  \n",
       "3              -1.10          13.9                68.296                  1  \n",
       "4              -1.10          13.9                68.296                  2  \n",
       "5              -1.10          13.9                68.296                  5  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f65c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d993a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
